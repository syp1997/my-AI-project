{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pynvml\n",
    "import time\n",
    " \n",
    "pynvml.nvmlInit()#初始化\n",
    "#设备情况\n",
    "deviceCount = pynvml.nvmlDeviceGetCount()\n",
    "print('GPU number：',deviceCount)\n",
    "for i in range(deviceCount):\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "    gpu_name = pynvml.nvmlDeviceGetName(handle)\n",
    "    print('GPU %d is :%s'%(i,gpu_name))\n",
    " \n",
    "    #显存信息\n",
    "    memo_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(\"GPU %d Memory Total: %.4f G\"%(i,memo_info.total/1024/1024/1000) )\n",
    "    print(\"GPU %d Memory Free: %.4f G\"%(i,memo_info.free/1024/1024/1000))\n",
    "    print(\"GPU %d Memory Used: %.4f G\"%(i,memo_info.used/1024/1024/1000))\n",
    " \n",
    "    #温度\n",
    "    Temperature = pynvml.nvmlDeviceGetTemperature(handle, 0)\n",
    "    print(\"Temperature is %.1f C\" %(Temperature))\n",
    " \n",
    "    #风扇转速\n",
    "    speed = pynvml.nvmlDeviceGetFanSpeed(handle)\n",
    "    print(\"Fan speed is \",speed)\n",
    " \n",
    "    #电源状态\n",
    "    power_ststus = pynvml.nvmlDeviceGetPowerState(handle)\n",
    "    print(\"Power ststus\", power_ststus)\n",
    "    \n",
    "for n in range(1000):\n",
    "    time.sleep(10)\n",
    "    memo_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(\"%d min: GPU Memory Used/Total: %.4f G/%.4f G\"%(n/6, memo_info.used/1024/1024/1000,memo_info.total/1024/1024/1000) )\n",
    "\n",
    "#关闭\n",
    "pynvml.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_memory(handle):\n",
    "    meminfo = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    free = meminfo.free/1024/1024/1000\n",
    "    return free\n",
    "\n",
    "pynvml.nvmlInit()\n",
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "print('Initial GPU memory：%.4f G'%get_gpu_memory(handle))\n",
    "torch.cuda.empty_cache()\n",
    "print('After torch.cuda.empty_cache, GPU memory：%.4f G' % get_gpu_memory(handle))\n",
    "# del(model)\n",
    "print('After del model, GPU memory：%.4f G'%get_gpu_memory(handle))\n",
    "pynvml.nvmlShutdown()  # 最后关闭管理工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
